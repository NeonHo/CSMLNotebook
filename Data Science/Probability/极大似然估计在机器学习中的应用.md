<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" class="logo" width="120"/>

# 极大似然估计在机器学习中的应用

极大似然估计（Maximum Likelihood Estimation，MLE）在机器学习中的应用非常广泛，核心思想是通过观测数据来估计模型参数，使得在该参数下观测数据出现的概率最大化。

---

## 极大似然估计在机器学习中的主要应用

1. **参数估计**
在机器学习中，很多模型都包含未知参数。极大似然估计通过定义似然函数（即给定参数时观测数据的联合概率），寻找使该似然函数值最大的参数，从而完成参数估计。
例如，线性回归[[Linear Regression]]、逻辑回归[[Logistic Regression]]、[[朴素贝叶斯]]、[[隐马尔可夫模型]]等都采用MLE方法估计参数。
2. **模型训练与优化**
训练过程就是最大化训练数据的对数似然函数。通过求解对数似然函数的导数，利用梯度下降、牛顿法等优化算法，得到最优参数。
[[数值优化算法——牛顿法]][[Section 5 Stochastic Gradient Descent]]
对数似然函数的凸性质保证了优化的稳定性和全局最优。
3. **概率模型学习**
MLE为概率模型提供了系统的参数学习方法，使得模型能够更好地拟合数据分布。
例如，隐变量模型（如高斯混合模型）和深度生成模型中，MLE是核心的训练方法。
4. **连接KL散度和最小化目标**
最大化似然等价于最小化模型分布与真实数据分布之间的KL散度，从信息论角度解释了MLE的合理性。
5. **适用于各种数据分布和模型结构**
MLE方法灵活，适合不同的概率分布假设和复杂模型，且随着样本量增大，估计值趋近真实参数。

---

## 具体流程示例

- 假设有参数化模型 \$ p(x|\theta) \$，数据集为 \$ D = \{x_1, x_2, ..., x_n\} \$。
- 构造似然函数：

$$
L(\theta) = \prod_{i=1}^n p(x_i|\theta)
$$
- 取对数得到对数似然函数：

$$
\ell(\theta) = \sum_{i=1}^n \log p(x_i|\theta)
$$
- 通过求导和数值优化，找到使 $\ell(\theta)$ 最大的 $\hat{\theta}$。

---

## 总结

极大似然估计是机器学习中参数估计和模型训练的基础方法，通过最大化观测数据的概率，帮助模型找到最合适的参数，提升模型的拟合能力和泛化性能。

---

### 参考

- CSDN博客《深度探索：机器学习中的最大似然估计（MLE）原理及其应用》[^1]
- CSDN博客《极大似然估计（Maximum-Likelihood）的理解》[^2]
- 掘金《最大似然估计：基本原理和实际应用》[^4]
- 博客园《机器学习——极大似然估计》[^3]

<div style="text-align: center">⁂</div>

[^1]: https://blog.csdn.net/qq_51320133/article/details/137912409

[^2]: https://blog.csdn.net/Flag_ing/article/details/122880229

[^3]: https://www.cnblogs.com/BlairGrowing/p/14877125.html

[^4]: https://juejin.cn/post/7321408980378075187

[^5]: https://www.cnblogs.com/LittleHann/p/7823421.html

[^6]: https://lulaoshi.info/deep-learning/linear-model/maximum-likelihood-estimation.html

[^7]: https://www.youtube.com/watch?v=BGnV4io38P4

[^8]: https://cloud.tencent.com/developer/article/1559960

