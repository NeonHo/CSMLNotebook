AIC（Akaike Information Criterion，赤池信息准则）和BIC（Bayesian Information Criterion，贝叶斯信息准则）是统计学中用于模型选择的重要指标，二者均通过权衡模型的拟合优度和复杂度，帮助研究者从多个候选模型中选择最优模型。


### 一、核心思想
模型选择的核心矛盾是**拟合优度与复杂度的平衡**：
- 复杂模型（如参数更多的模型）通常能更好地拟合现有数据，但可能存在过拟合（对噪声敏感，泛化能力差）；
- 简单模型泛化能力较强，但可能拟合不足。

AIC和BIC均通过量化“拟合优度损失”与“模型复杂度惩罚”的总和，实现对模型的客观评价，**数值越小的模型越优**。


### 二、计算公式
#### 1. AIC的定义
$$
\text{AIC} = 2k - 2\ln(L)
$$
其中：
- $k$ 是模型中待估计的参数数量（模型复杂度）；
- $L$ 是模型的似然函数值（反映模型对数据的拟合优度，$L$ 越大，拟合越好）。

#### 2. BIC的定义
$$
\text{BIC} = k\ln(n) - 2\ln(L)
$$
其中：
- $k$ 和 $L$ 的含义与AIC一致；
- $n$ 是样本量，$\ln(n)$ 是对模型复杂度的惩罚项（样本量越大，惩罚越重）。


### 三、关键区别
| 维度         | AIC                          | BIC                          |
|--------------|------------------------------|------------------------------|
| **惩罚力度** | 对参数的惩罚是固定的（$2k$） | 对参数的惩罚随样本量增大而增大（$k\ln(n)$），当 $n > 7$ 时，惩罚比AIC更严厉 |
| **适用场景** | 更注重模型的预测性能（泛化能力） | 更适合样本量较大的场景，倾向于选择更简单的模型（避免过拟合） |
| **理论基础** | 基于信息论，近似最小化“信息损失” | 基于贝叶斯理论，近似最小化模型的后验概率损失 |


### 四、应用逻辑
1. 对每个候选模型计算AIC或BIC值；
2. 选择AIC/BIC值最小的模型。

例如：
- 若模型1的AIC=100，模型2的AIC=90，则模型2更优；
- 若样本量很大（如 $n=1000$），BIC对复杂模型的惩罚远大于AIC，可能会选择参数更少的模型。


### 五、注意事项
1. **适用条件**：AIC和BIC仅适用于基于似然函数的模型（如线性回归、逻辑回归、时间序列模型等）；
2. **相对性**：二者均是“相对指标”，仅能比较同一数据集上的不同模型，无法单独评价某个模型的绝对优劣；
3. **互补性**：实际应用中常同时计算AIC和BIC，若结果一致，模型选择更可靠；若结果冲突，需结合研究目的（如侧重预测还是解释）判断。


### 六、总结
- AIC更适合小样本或需要强预测能力的场景，对复杂模型的包容度较高；
- BIC更适合大样本或追求模型简洁性的场景，对复杂模型的惩罚更严厉。

二者共同为模型选择提供了量化标准，避免了仅凭主观判断的局限性。