集成学习通过组合多个基模型的预测结果来提升整体性能，而**结合策略**是决定如何整合基模型输出的核心环节。常见的结合策略包括**平均法**（适用于回归任务）、**投票法**（适用于分类任务），以及更复杂的堆叠法（Stacking）等。以下详细解析这些策略：


### 一、平均法（适用于回归任务）
平均法通过对多个基模型的预测结果进行平均，降低单个模型的随机误差，提高预测稳定性。根据是否赋予基模型权重，可分为**简单平均**和**加权平均**。

#### 1. 简单平均（Simple Averaging）
所有基模型的预测结果被赋予相同权重，直接取算术平均值作为最终输出。  
设基模型数量为`k`，第`i`个模型的预测值为`y_i`，则最终预测`y`为：  
$$
y = \frac{1}{k} \sum_{i=1}^{k} y_i
$$  

**特点**：  
- 计算简单，无需额外训练；  
- 假设所有基模型性能相近，若模型差异大，效果可能不佳。

**示例**：3个模型对房价的预测分别为100万、110万、105万，简单平均结果为（100+110+105）/3 = 105万。


#### 2. 加权平均（Weighted Averaging）
根据基模型的性能（如准确率、误差）赋予不同权重，性能更优的模型权重更高。  
设第`i`个模型的权重为`w_i`（满足$\sum_{i=1}^{k} w_i = 1且w_i ≥ 0$），则最终预测`y`为：  
$$
y = \sum_{i=1}^{k} w_i \cdot y_i
$$  

**权重确定方式**：  
- 手动设定（基于领域知识）；  
- 通过交叉验证优化（如最小化验证集误差）。  

**特点**：  
- 比简单平均更灵活，理论上性能更优；  
- 权重选择不当可能导致过拟合（如过度依赖某一模型）。


### 二、投票法（适用于分类任务）
投票法通过整合多个基模型的类别预测，确定最终类别。根据投票依据是“类别标签”还是“类别概率”，可分为**硬投票**和**软投票**。

#### 1. 硬投票（Hard Voting）
每个基模型直接输出预测的类别标签，最终类别由“多数票”决定（即得票最多的类别）。  
- 二分类场景：超过半数的模型预测为某类，则最终结果为该类；  
- 多分类场景：得票最多的类别为最终结果（可能存在平局，需额外规则处理）。  

**示例**：5个模型对某样本的预测为`[“正类”, “正类”, “负类”, “正类”, “负类”]`，“正类”得3票，最终结果为“正类”。  

**特点**：  
- 简单直观，适用于模型输出类别明确的场景；  
- 未考虑模型的置信度差异（如一个高准确率模型和一个低准确率模型的投票权重相同）。


#### 2. 软投票（Soft Voting）
每个基模型输出各类别的概率（如$P(c|x)$，表示样本`x`属于类别`c`的概率），最终类别由概率之和最大的类别决定（或加权概率和）。  
设类别集合为$C = {c_1, c_2, ..., c_m}$，第`i`个模型对类别$c_j$的预测概率为$P_i(c_j|x)$，则：  
- 简单软投票：最终概率$P(c_j|x) = \frac{1}{k} \sum_{i=1}^{k} P_i(c_j|x)$，选择$P(c_j|x)$最大的$c_j$；  
- 加权软投票：引入权重$w_i$，最终概率$P(c_j|x) = \sum_{i=1}^{k} w_i \cdot P_i(c_j|x)$，选择概率最大的类别。  

**特点**：  
- 利用了模型的置信度信息，通常比硬投票更准确；  
- 要求基模型能输出可靠的概率（如逻辑回归[[Logistic Regression]]、[[SVM]]的概率输出，而非决策树的硬标签）。


### 三、其他结合策略
#### 1. 堆叠法（Stacking）
堆叠法（又称“元学习”）引入**元模型**（Meta-model），将基模型的预测结果作为新特征，训练元模型来输出最终预测。  
- 步骤：  
  1. 用训练集训练多个基模型，得到它们在训练集和验证集上的预测结果；  
  2. 将基模型的预测结果作为输入特征，原始特征可选是否加入，训练元模型（如逻辑回归、随机森林）；  
  3. 测试时，先由基模型预测，再输入元模型得到最终结果。  

**特点**：  
- 灵活性高，可学习基模型之间的复杂关系；  
- 实现复杂，需避免过拟合（如使用交叉验证生成基模型的预测）。


#### 2. 排序融合（适用于排序任务）
在推荐、搜索等场景中，需对物品排序，结合策略可采用：  
- 加权评分：对每个模型的排序分数加权求和；  
- 等级融合：将多个模型的排序结果转化为等级，再综合等级排序。  


### 四、策略选择与注意事项
1. **模型多样性**：结合策略的效果依赖于基模型的“多样性”（即模型误差不高度相关）。若模型高度一致，简单平均/投票的提升有限。  
2. **任务类型**：回归用平均法，分类用投票法（软投票通常优于硬投票，若模型概率可靠）。  
3. **权重设置**：加权策略需谨慎，避免过度拟合（可通过交叉验证调整权重）。  
4. **冲突处理**：投票出现平局时，可引入额外规则（如选择置信度最高的类别，或默认类别）。  


### 总结
| 策略         | 适用任务   | 核心逻辑                     | 优势                     | 劣势                     |
|--------------|------------|------------------------------|--------------------------|--------------------------|
| 简单平均     | 回归       | 算术平均基模型预测值         | 简单、无参数             | 未区分模型性能           |
| 加权平均     | 回归       | 按权重加权平均               | 灵活，性能更优           | 权重选择复杂             |
| 硬投票       | 分类       | 多数票决定类别               | 直观，适用于标签输出     | 未利用概率信息           |
| 软投票       | 分类       | 概率加权求和，选最大概率类别 | 利用置信度，更准确       | 依赖模型输出可靠概率     |
| 堆叠法       | 回归/分类  | 用元模型学习基模型输出       | 可捕捉复杂关系           | 实现复杂，易过拟合       |

结合策略的核心目标是“扬长避短”，通过整合不同模型的优势来提升整体性能，实际应用中需根据数据特点和业务需求选择合适的方法。
# 学习法
