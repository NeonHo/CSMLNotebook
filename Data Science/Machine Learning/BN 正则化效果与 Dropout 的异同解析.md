[[Batch Normalization]]（BN）的正则化效果与[[Dropout]]虽机制不同，但核心均通过引入**训练过程的随机性**或**约束模型对输入细节的过度依赖**，从而抑制过拟合，增强模型泛化能力。具体原因可从以下角度解析：

### 1. **训练时的随机性引入：批次统计量的波动**  
BN在训练阶段的核心计算依赖于**当前批次的均值和方差**（而非全局统计量）。由于不同批次的样本组成不同，计算出的均值$\mu_B$和方差$\sigma_B^2$会随批次变化，导致同一输入样本在不同批次中被归一化后的结果存在差异：  
- 例如，一个样本$x_i$在批次A中可能被归一化为$\hat{x}_{i_A}$ ，在批次B中因批次均值/方差不同，被归一化为$\hat{x}_{i_B}$，两者存在微小差异。  
- 这种**由批次随机性导致的输入扰动**，相当于给模型训练过程加入了“噪声”，迫使模型学习对这种波动不敏感的鲁棒特征（而非过度拟合某一批次的具体细节）。  

这与Dropout的随机性类似：Dropout通过随机丢弃神经元引入噪声，BN则通过批次统计量的波动引入噪声，两者均通过“破坏确定性”防止模型记住训练数据的细节。

### 2. **减少神经元对特定输入模式的依赖**  
Dropout的正则化本质是**阻止神经元之间的共适应**（co-adaptation）：由于神经元可能被随机丢弃，网络无法依赖特定神经元的输出，必须学习更通用的特征组合。  

BN虽不直接丢弃神经元，但通过归一化操作**削弱了神经元对输入绝对数值的依赖**，转而关注相对分布：  
- 假设某神经元的输入在未归一化时依赖于前层输出的“绝对大小”（如必须大于某个阈值才激活），BN会将输入标准化到均值0、方差1附近，使神经元更关注输入的“相对变化”（而非绝对数值）。  
- 同时，由于归一化依赖批次内的其他样本，神经元的输出不仅受自身输入影响，还受同批次其他样本的间接影响（例如，批次中存在异常值时，均值/方差的偏移会“稀释”该异常值对当前样本的影响）。这种“跨样本依赖”迫使神经元学习更普遍的模式，减少对个别样本的过度拟合。

### 3. **训练与推理的差异带来的隐式约束**  
BN在训练和推理阶段的计算存在差异：  
- 训练时用**批次统计量**（$\mu_B, \sigma_B^2$），推理时用**全局移动平均统计量**（running_mean, running_var）。  
- 这种差异意味着，模型在训练时需要适应“批次波动的统计量”，而推理时则需在“稳定的全局统计量”下工作。这种“适应不一致性”会对模型施加隐式约束：只有当模型学习到的特征在不同批次统计量下均保持有效时，才能在推理时表现良好。  

这种约束类似于“数据增强”的效果——通过人为制造训练与推理的差异，迫使模型学习更鲁棒的特征，间接起到正则化作用。

### 4. **与Dropout的对比：机制不同，但目标一致**  

| 特性                | Dropout                          | Batch Normalization                  |
|---------------------|----------------------------------|--------------------------------------|
| **随机性来源**      | 随机丢弃神经元（0/1掩码）        | 批次统计量的波动（均值/方差变化）    |
| **作用对象**        | 神经元输出（直接抑制激活）       | 输入数据分布（间接调整激活范围）      |
| **正则化本质**      | 破坏神经元共适应，强制特征冗余   | 引入输入扰动，削弱对绝对数值的依赖    |
| **副作用**          | 可能增加训练时间（需更多迭代）   | 可能因小批次统计不准降低效果          |

尽管机制不同，但两者均通过**引入训练过程的不确定性**，限制模型对训练数据细节的过度拟合，最终达到正则化效果。

### 总结  
BN的正则化效果源于其训练过程中**批次统计量的随机性**、**对神经元依赖关系的削弱**，以及**训练与推理的统计差异**。这些因素共同作用，使模型在学习特征时更关注通用模式而非个别样本细节，从而与Dropout类似，起到抑制过拟合、增强泛化能力的作用。  

不过需注意：BN的正则化效果通常弱于Dropout，且两者同时使用可能存在冲突（如部分研究指出BN会削弱Dropout的随机性），实际应用中需根据场景调整。