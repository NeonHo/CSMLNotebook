少样本学习（Few-Shot Learning）是机器学习领域的一个重要分支，其核心目标是**让模型仅通过少量标注样本（通常每个类别 5–20 个样本，甚至更少）就能快速学习并泛化到新任务**。这种能力与人类的学习方式高度相似——人类可以通过几个例子快速理解新概念（比如教孩子认识“斑马”，只需看几张图片就能记住），而传统机器学习模型往往需要大量标注数据才能表现良好。

---

### 一、核心动机：解决“数据稀缺”问题

传统深度学习模型（如 [[CNN]]、[[RNN]]）的成功严重依赖大规模标注数据（例如 ImageNet 有 1400 万张图片），但在很多实际场景中，标注数据往往非常稀缺：

- **图像识别**：新物种、罕见疾病的医学影像、工业质检中的新型缺陷等，每个类别可能只有几张样本。  
- **自然语言处理**：低资源语言（如非洲的斯瓦希里语）的翻译、特定领域（如法律）的文本分类，标注成本极高。  
- **推荐系统**：新用户 / 新商品的“冷启动”问题，缺乏历史交互数据。

少样本学习正是为了突破“数据依赖”的瓶颈，让模型在数据有限时仍能有效学习。

---

### 二、与相关概念的区别

少样本学习常与以下概念并列，需明确区分：

| 名称         | 每类样本数量 | 是否有标注 | 核心要点示例 |
|--------------|--------------|------------|--------------|
| **零样本学习** | 0            | 否         | 仅靠类别描述识别“斑马”（如“黑白条纹、类似马的动物”） |
| **单样本学习** | 1            | 是         | 人脸识别用一张身份证照片匹配现场人脸 |
| **少样本学习** | 5–20         | 是         | 5-way 5-shot：5 类，每类 5 个样本 |
| **传统监督学习** | 数百~数千 | 是         | ImageNet 每类 600–1000 张图片 |

---

### 三、核心挑战

数据稀缺带来的连锁难题：

1. **过拟合风险**：少量样本无法描述整体分布，模型易记忆细节而非通用规律。  
2. **特征泛化难**：需提取跨任务通用特征，而非仅适配当前小数据集。  
3. **任务适应性弱**：传统模型需大量重训练，成本高。

---

### 四、少样本学习的主要方法

目前解决方案可分为三大类：**元学习、预训练与微调、数据增强**。

#### 1. 元学习（Meta-Learning）：“学习如何学习”
[[Meta Learning]]
通过大量“小任务”训练模型学会通用学习策略，再快速适配新任务。

- **MAML**（Model-Agnostic Meta-Learning）  
  - 目标：找到对微调敏感的初始化参数 $θ_0$。  
  - 流程：  
    1. 任务采样 → 内循环：少步梯度更新 → 外循环：验证集损失更新 $θ_0$。  
    2. 测试时：在新任务上用 $θ_0$ 微调 1–2 步即可。  

- **原型网络（Prototypical Networks）**  
  - 为每类计算原型 $c_k = \frac{1}{|S_k|}\sum_{x\in S_k} f_\phi(x)$，新样本以最近原型分类。  

- **匹配网络（Matching Networks）**  
  - 用注意力机制直接匹配支持集与查询样本，相似度由神经网络学习。

#### 2. 预训练与微调（Pre-training & Fine-tuning）

先用大规模数据训练通用特征提取器，再用少量新任务样本微调。

- 流程：  
  1. 预训练：在 ImageNet、Wikipedia 等海量数据上训练模型（如 ResNet、BERT）。  
  2. 微调：冻结大部分参数，仅用少量新数据微调顶层或少量层。  
- 优势：工程简单，NLP 领域尤其成功（GPT-4、CLIP）。

#### 3. 数据增强（Data Augmentation）

通过生成“可信新样本”扩展数据量。

| 领域 | 常用方法                             |
| --- | -------------------------------- |
| 图像 | 旋转、裁剪、Mixup、[[GAN]] 生成 |
| 文本 | 同义词替换、回译、GPT 生成同主题句子             |

---

### 五、典型应用场景

- **图像识别**：新类别快速分类、罕见疾病影像诊断。  
- **NLP**：低资源语言翻译、小样本意图识别。  
- **机器人**：少量演示学会开门、叠衣服。  
- **推荐系统**：新用户冷启动，快速推荐偏好商品。

---

### 六、评估与数据集

| 数据集        | 任务类型 | 设置示例 |
|---------------|----------|----------|
| **Omniglot**  | 手写字符 | 1623 类，每类 20 张，5-way 5-shot |
| **Mini-ImageNet** | 图像分类 | 100 类，每类 600 张，评估 5-way 5-shot |
| **FewRel**    | 文本关系 | 每类 40 样本 |
| **GLUE 少样本子集** | NLP 任务 | 情感分析、问答 |

评估指标：**新任务上的准确率**（如 5-way 5-shot accuracy）。

---

### 七、总结与展望

少样本学习目标：像人类一样“举一反三”。当前热点：

- 元学习 + 预训练：用元学习优化预训练模型的微调策略。  
- 多模态预训练：CLIP、FLAVA 等通用特征表示。  
- 因果推理：从少量样本学习因果关系而非表面关联。  
- 记忆机制：动态存储和调用过往经验。

最终愿景：在真实世界中，以极少数据灵活适应各种新任务。