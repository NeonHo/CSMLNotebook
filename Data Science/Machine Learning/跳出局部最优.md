- 引入并设置动量
- 设置不同的权重初始值
- 随机梯度下降[[Section 5 Stochastic Gradient Descent]]

# Batch Size 对局部最优的影响

增大 Batch Size 通常不能克服局部最优点，甚至可能使模型更容易被困在局部最优或泛化能力较差的解中。以下从优化机制、梯度特性、实际影响等角度展开分析：

## 一、Batch Size 与优化动态的核心逻辑

### 1. 梯度估计的噪声特性
- **小 Batch Size**（如 Batch = 32）：  
  每次迭代使用少量样本计算梯度，梯度估计存在**随机性噪声**。这种噪声相当于为优化过程引入“扰动”，可能帮助模型跳出浅的局部最优或鞍点（如通过随机波动越过能量壁垒）。  
  **类比**：如同在崎岖地形中行走时，小步幅的随机晃动可能绕过小坑洼。

- **大 Batch Size**（如 Batch = 1024）：  
  梯度基于大量样本平均，估计更**精确但缺乏随机性**。此时优化路径更“确定”，容易沿着当前梯度方向快速收敛到最近的局部最优，而难以逃离该区域。  
  **类比**：大步幅直线行走时，容易陷入最近的坑洼而无法自拔。

### 2. 优化算法的更新方向
局部最优的本质是梯度接近零的区域。大 Batch Size 的梯度更新更“陡峭”地指向当前局部最优，而小 Batch Size 的噪声可能使梯度在局部最优附近震荡，从而有机会探索周围区域。

## 二、大 Batch Size 对局部最优的具体影响

### 1. 更易陷入泛化能力差的局部最优
研究表明（如 [ICML 2018 论文](https://arxiv.org/abs/1804.08838)）：大 Batch Size 训练的模型倾向于收敛到**尖锐最小值**（Sharp Minima），即局部最优附近梯度变化剧烈，对扰动敏感，泛化能力较差；而小 Batch Size 更可能收敛到**平坦最小值**（Flat Minima），模型鲁棒性更强。
- **尖锐最小值**：类似山谷中的深窄坑，参数微小变化会导致损失剧增。
- **平坦最小值**：类似平缓的盆地，参数波动对损失影响较小，更可能对应泛化良好的解。

### 2. 对鞍点的逃离能力下降
鞍点（Saddle Point）是梯度为零但非极值点的区域（如马鞍的中心）。小 Batch Size 的噪声可能帮助模型越过鞍点，而大 Batch Size 的确定性梯度容易在鞍点附近停滞。

## 三、反例与特殊场景

### 1. 理论上的可能性：仅当局部最优为全局最优时
若问题本身存在唯一全局最优（如线性回归），大 Batch Size 可直接收敛到该点，但这属于特例，而非“克服局部最优”的场景。

### 2. 结合其他技术的间接作用
若大 Batch Size 搭配**随机权重初始化**、**正则化（如 [[Dropout]]）** 或**学习率调度策略**，可能间接提升逃离局部最优的能力，但核心作用仍来自于这些附加技术，而非 Batch Size 本身。

## 四、实践建议：平衡 Batch Size 与优化效果

| 目标                | 推荐 Batch Size 策略                | 原理说明                          |
|---------------------|-------------------------------------|-----------------------------------|
| 提升模型泛化能力    | 采用中小 Batch Size（如 32-256）     | 利用噪声探索更优解空间            |
| 加速训练收敛速度    | 采用大 Batch Size（如 512+）并调整学习率 | 减少梯度估计方差，适合工程落地    |
| 逃离复杂局部最优    | 结合小 Batch Size + 动态扰动策略      | 如 Cyclical LR、热重启 SGD 等     |

## 五、总结
增大 Batch Size 不能克服局部最优点，其本质原因是减少了优化过程的随机性，导致模型更易被困在当前局部最优区域。若需提升模型跳出局部最优的能力，更有效的方法是引入随机性（如小 Batch Size、随机梯度扰动）或设计更优的优化策略（如动量法、自适应梯度算法）。在实际应用中，需根据任务需求平衡 Batch Size 的大小，在收敛速度与解的质量之间找到折中方案。