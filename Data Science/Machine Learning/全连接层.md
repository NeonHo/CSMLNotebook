多层感知机（[[MLP]]，Multilayer Perceptron）本质上是由**全连接层（Fully Connected Layer）** 堆叠而成的神经网络。

---

### 1. 全连接层的定义

全连接层中，**每个神经元与前一层的所有神经元都存在连接**，即该层的每个神经元的输入是前一层所有神经元输出的加权和（再经过激活函数）。  
- 例如，若前一层有 $n$ 个神经元，当前全连接层有 $m$ 个神经元，则两者之间的连接权重参数为 $n \times m$ 个（外加 $m$ 个偏置参数）。

---

### 2. MLP 的结构与全连接层的关系

MLP 的基本结构可拆解为：  
- **输入层**：接收原始数据（如特征向量），本身不涉及计算，仅传递输入。  
- **隐藏层**：至少包含 1 层全连接层，通过激活函数（如 ReLU、Sigmoid）引入非线性，实现特征的复杂变换。  
- **输出层**：最后一层全连接层，输出模型的预测结果（如分类任务的类别概率、回归任务的连续值）。  

**核心特点**：所有隐藏层和输出层均为全连接层，层与层之间不存在局部连接（如 CNN 的卷积层）或跳跃连接（如 ResNet 的残差连接）等特殊结构。

---

### 3. MLP 与其他网络的区别

与 [[CNN]]、[[RNN]] 等网络相比，MLP 的“全连接”特性是其最显著的标志：  
- CNN 通过卷积层的局部连接减少参数，适用于网格数据（如图像）；  
- RNN 通过时序连接处理序列数据（如文本）；  
- 而 MLP 的全连接结构使其更适用于简单的向量输入（如表格数据），但在处理高维数据（如图像）时会因参数爆炸而效率低下。

---

### 结论

全连接层是 MLP 的核心组成单元，MLP 可视为“仅由全连接层构成的深度神经网络”。