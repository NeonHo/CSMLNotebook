# Apriori算法：关联规则挖掘的经典方法

## 一、算法背景与核心思想

Apriori算法由R. Agrawal等人于1993年提出，旨在从交易数据中挖掘频繁项集（Frequent Itemset），进而生成关联规则（如“买啤酒的人也可能买尿布”）。
Apriori算法是一种挖掘关联规则的频繁项集算法,其核心思想是：
	通过**候选集生成**和**情节的向下封闭检测**两个阶段来挖掘频繁项集。

其核心基于**Apriori性质**：
- **频繁项集的所有子集必为频繁项集**；
- **非频繁项集的超集必为非频繁项集**。

该性质用于剪枝，避免枚举所有可能的项集，大幅减少计算量。

## 二、算法流程详解

### 1. 数据预处理
[[数据预处理]]
- 将交易数据转换为项集（Itemset）形式，每个交易包含若干项（Item），如：
```
交易1: {面包, 牛奶} 
交易2: {面包, 尿布, 啤酒, 鸡蛋}
```
- 定义最小支持度阈值（Min Support）和最小置信度阈值（Min Confidence），用于筛选频繁项集和有效规则。

### 2. 生成频繁1-项集
- 统计每个单项的支持度（出现频率），筛选出支持度≥Min Support的项，构成频繁1-项集。
- **支持度计算**：

$$
\text{Support}(X) = \frac{\text{包含X的交易数}}{\text{总交易数}}
$$

### 3. 迭代生成频繁k-项集（k≥2）

以生成频繁2-项集为例：
1. **连接步骤（Join）**：
 将两个频繁1-项集合并为2-项集，如`{面包}`和`{牛奶}`合并为`{面包, 牛奶}`。
2. **剪枝步骤（Prune）**：
 若2-项集的某个子集（如`{面包}`或`{牛奶}`）非频繁，则剔除该2-项集（基于Apriori性质）。
3. **支持度筛选**：
 统计所有候选2-项集的支持度，保留≥Min Support的频繁2-项集。
4. **迭代直至无法生成更大项集**：
 重复连接-剪枝-筛选步骤，生成频繁3-项集、4-项集等，直到k-项集为空。
[[Apriori算法中,候选项集划分为不同的桶存放在Hash树中]]
### 4. 生成关联规则
对每个频繁k-项集X，生成所有非空真子集A⊂X，计算规则`A→(X-A)`的置信度，保留≥Min Confidence的规则：
- **置信度计算**：

$$
\text{Confidence}(A→B) = \frac{\text{Support}(A∪B)}{\text{Support}(A)}
$$

- 示例：若频繁项集`{面包, 牛奶}`的支持度为0.6，`{面包}`的支持度为0.8，则规则`面包→牛奶`的置信度为0.6/0.8=0.75。

## 三、算法示例：超市购物篮分析

假设交易数据如下（Min Support=0.3，Min Confidence=0.6）：

| 交易ID | 商品列表               |
|--------|------------------------|
| T1     | {面包, 牛奶}           |
| T2     | {面包, 尿布, 啤酒, 鸡蛋} |
| T3     | {牛奶, 尿布, 啤酒, 可乐} |
| T4     | {面包, 牛奶, 尿布, 啤酒} |
| T5     | {面包, 牛奶, 尿布, 可乐} |

##### 1. 生成频繁1-项集
- 统计各商品支持度：
- 面包：4/5=0.8，牛奶：4/5=0.8，尿布：4/5=0.8，啤酒：3/5=0.6，鸡蛋：1/5=0.2，可乐：2/5=0.4
- 频繁1-项集：`{面包}, {牛奶}, {尿布}, {啤酒}, {可乐}`（鸡蛋支持度0.2<0.3被剔除）。

##### 2. 生成频繁2-项集
- **连接步骤**：合并频繁1-项集，生成候选2-项集（共C(5,2)=10个）。
- **剪枝步骤**：所有子集均为频繁1-项集，无需剪枝。
- **支持度计算**：
- `{面包, 牛奶}`：3/5=0.6，`{面包, 尿布}`：3/5=0.6，`{面包, 啤酒}`：3/5=0.6，`{面包, 可乐}`：2/5=0.4，
- `{牛奶, 尿布}`：3/5=0.6，`{牛奶, 啤酒}`：3/5=0.6，`{牛奶, 可乐}`：2/5=0.4，
- `{尿布, 啤酒}`：3/5=0.6，`{尿布, 可乐}`：2/5=0.4，`{啤酒, 可乐}`：1/5=0.2（剔除）。
- 频繁2-项集：除`{啤酒, 可乐}`外的9个项集。

##### 3. 生成频繁3-项集（以`{面包, 牛奶, 尿布}`为例）
- 支持度：3/5=0.6≥0.3，为频繁3-项集；
- 其他候选3-项集（如`{面包, 牛奶, 啤酒}`）支持度=2/5=0.4≥0.3，也为频繁项集。

##### 4. 生成关联规则
以频繁3-项集`{面包, 牛奶, 尿布}`为例：
- 规则1：`{面包, 牛奶}→尿布`
置信度=0.6/0.6=1.0≥0.6，有效；
- 规则2：`{面包}→{牛奶, 尿布}`
置信度=0.6/0.8=0.75≥0.6，有效。

## 四、算法优缺点与优化方向

| **优点**                          | **缺点**                          | **优化方法**                          |
|-----------------------------------|-----------------------------------|---------------------------------------|
| 原理简单，易实现                  | 多次扫描数据库，I/O开销大        | 利用FP-Growth算法构建前缀树减少扫描  |
| 基于Apriori性质剪枝，减少计算量   | 当项集维度高时，候选集爆炸        | 使用垂直数据表示（如Eclat算法）      |
| 支持度-置信度框架直观易懂        | 难以处理稀疏数据和连续特征        | 引入频繁模式树（FP-Tree）压缩存储    |

## 五、实际应用场景

1. **零售行业**：购物篮分析，优化商品摆放和促销策略（如啤酒与尿布捆绑销售）；
2. **电商推荐**：根据用户购买记录生成关联推荐（如“买了A的用户也买了B”）；
3. **网络安全**：挖掘用户行为模式，检测异常交易；
4. **医疗诊断**：分析症状与疾病的关联规则，辅助诊断。

## 总结

Apriori算法通过迭代生成频繁项集和剪枝策略，高效挖掘数据中的关联模式，是关联规则挖掘的基石。尽管存在候选集爆炸和多次扫描数据库的缺点，但其思想启发了后续FP-Growth、Eclat等优化算法。在实际应用中，合理设置支持度和置信度阈值，结合数据特性选择优化策略，是发挥Apriori算法效能的关键。