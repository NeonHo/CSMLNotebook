重参数技巧（Reparameterization Trick）是一种在深度学习中用于解决模型训练过程中随机性操作导致的梯度不可导问题的数学技巧。以下是对它的详细解释：

### 问题背景
在一些涉及概率生成的模型中，如变分自编码器（VAE），需要从潜在变量的分布中采样。假设潜变量$z$服从分布$q_{\varphi}(z|x)$，其中$\varphi$是分布的参数。由于$q_{\varphi}(z|x)$本身是$\varphi$的函数，在计算梯度时，无法直接将梯度移入期望内部，即期望和梯度操作不可互换，这使得传统的蒙特卡洛近似和反向传播难以直接应用，导致梯度计算困难。

### 核心思想
重参数化技巧的核心是将潜变量$z \sim q_{\varphi}(z|x)$表示为一个与$\varphi$和$x$相关的可微变换函数。具体来说，引入一个独立的随机变量$\epsilon$，服从某个固定分布$p(\epsilon)$（如标准正态分布$\mathcal{N}(0, I)$），将$z$表示为$z = g(\epsilon, \varphi, x)$，其中$g$是一个可微且可逆的函数。这样，$z$的随机性被转移到$\epsilon$上，而$z$本身变为$\varphi$的确定性函数，便于进行梯度计算。

### 以正态分布为例的重参数化
假设$q_{\varphi}(z|x) = \mathcal{N}(z|\mu, \text{diag}(\sigma^{2}))$，其中$\varphi = (\mu, \sigma^{2})$。可以定义$z = g(\epsilon, \varphi, x)=\mu+\sigma \odot \epsilon$，其中$\epsilon \sim \mathcal{N}(0, I)$，$\odot$表示逐元素相乘。
- **验证变换的正确性**：
    - 首先求逆变换，由$z = \mu+\sigma \odot \epsilon$可得$\epsilon=\frac{z - \mu}{\sigma}$。
    - 然后计算雅可比行列式，$\frac{\partial z}{\partial \epsilon}=\text{diag}(\sigma)$，所以$\det(\frac{\partial z}{\partial \epsilon})=\prod_{i}\sigma_{i}$。
    - 已知$q_{\varphi}(z|x)=\prod_{i = 1}^{d}\frac{1}{\sqrt{2\pi\sigma_{i}^{2}}}\exp(-\frac{(z_{i}-\mu_{i})^{2}}{2\sigma_{i}^{2}})$，代入$q_{\varphi}(z|x) \cdot |\det(\frac{\partial z}{\partial \epsilon})|$可得：
$$
\begin{align*}
&(\prod_{i = 1}^{d}\frac{1}{\sqrt{2\pi\sigma_{i}^{2}}}\exp(-\frac{(z_{i}-\mu_{i})^{2}}{2\sigma_{i}^{2}}))\cdot(\prod_{i = 1}^{d}\sigma_{i})\\
=&\frac{1}{(2\pi)^{d/2}}\exp(-\frac{\|\epsilon\|^{2}}{2})\\
=&\mathcal{N}(0, I)\\
=&p(\epsilon)
\end{align*}
$$
这表明该变换满足要求。
- **重参数化后的梯度计算**：
通过重参数化，期望$\mathbb{E}_{q_{\varphi}(z|x)}(f(z))$可转换为关于$\epsilon$的期望。设$z = g(\epsilon, \varphi, x)$，则
$$
\begin{align*}
\mathbb{E}_{q_{\varphi}(z|x)}(f(z))&=\int f(z)q_{\varphi}(z|x)dz\\
&=\int f(g(\epsilon))q_{\varphi}(g(\epsilon)|x)|\det(\frac{\partial g(\epsilon)}{\partial \epsilon})|d\epsilon\\
&=\int f(g(\epsilon))p(\epsilon)d\epsilon
\end{align*}
$$
这样就可以通过对$\epsilon$采样来近似计算期望，进而进行梯度计算，使得梯度能够通过$\mu$和$\sigma$传播，实现端到端的训练。

### 优点
- **可导性**：将采样过程分解为确定性变换和随机噪声，使得整个采样过程可导，解决了因随机采样导致的梯度不可导问题。
- **稳定性**：避免了直接对随机采样结果求导，提高了训练的稳定性。
- **灵活性**：可以轻松扩展到其他分布，如均匀分布、指数分布、伯努利分布等，只需找到合适的重参数化形式。

### 应用场景
- **变分自编码器（[[Variational Auto-encoder]]）**：编码器输出$\mu$和$\log\sigma^{2}$，通过重参数化采样生成潜在变量$z$，解码器基于$z$重构输入数据。
- **强化学习[[Reinforce Learning]]（策略梯度方法）**：策略网络输出动作分布的参数，通过重参数化采样动作，使梯度可传回策略网络，从而更新策略网络的参数。
- **生成对抗网络（[[GAN]]）**：某些GAN变种通过重参数化生成器的输入噪声，提升训练的稳定性。