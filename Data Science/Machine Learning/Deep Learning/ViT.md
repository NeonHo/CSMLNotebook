[在ViT（Vision Transformer）模型中，额外加入一个cls token（类别标记）的主要目的是聚合全局信息](https://zhuanlan.zhihu.com/p/445122996)[1](https://zhuanlan.zhihu.com/p/445122996)[2](https://www.zhihu.com/question/458021580)[3](https://zhuanlan.zhihu.com/p/440294002)[4](https://zhuanlan.zhihu.com/p/536227229)[。ViT模型将一张图片切成多个小块，每个小块都被视为一个token。然而，每个token只能表示图片的局部信息。cls token在进入encoder之前与图片的所有小块进行了加权整合，其权重由attention机制自动学习](https://zhuanlan.zhihu.com/p/445122996)[2](https://www.zhihu.com/question/458021580)[。因此，ViT模型学到的cls token集成了所有图片块的信息，即具有全局性，用它来预测整张图的label更合理](https://zhuanlan.zhihu.com/p/445122996)[2](https://www.zhihu.com/question/458021580)。

[此外，cls token与图像无关，它是随机生成的，不基于图像内容，因此可以避免对sequence中某个特定token的偏向性](https://blog.csdn.net/gltangwq/article/details/124950935)[5](https://blog.csdn.net/gltangwq/article/details/124950935)[。cls token对所有其他token上的信息做汇聚（全局特征聚合），cls token（第0个token）使用固定的位置编码能够避免输出受到位置编码的干扰](https://blog.csdn.net/gltangwq/article/details/124950935)[5](https://blog.csdn.net/gltangwq/article/details/124950935)。

[需要注意的是，虽然cls token在ViT模型中起着重要的作用，但在某些任务中，例如语义分割，可能并不需要cls token](https://zhuanlan.zhihu.com/p/445122996)[2](https://www.zhihu.com/question/458021580)[。此外，ViT的原作者指出：使用图片所有小块token的平均来做预测和用cls token效果差不多](https://zhuanlan.zhihu.com/p/445122996)[2](https://www.zhihu.com/question/458021580)[。这是因为平均所有小块的token本质也是全局化所有图片块，此时的每个小块的权重都是相同的（而不是像ViT中用attention自动学的）](https://zhuanlan.zhihu.com/p/445122996)[2](https://www.zhihu.com/question/458021580)[。总的来说，cls token在计算机视觉的transform中，只是用在分类任务中的一个工具](https://zhuanlan.zhihu.com/p/445122996)[2](https://www.zhihu.com/question/458021580)[。](https://zhuanlan.zhihu.com/p/445122996)[1](https://zhuanlan.zhihu.com/p/445122996)[2](https://www.zhihu.com/question/458021580)[3](https://zhuanlan.zhihu.com/p/440294002)[4](https://zhuanlan.zhihu.com/p/536227229)[5](https://blog.csdn.net/gltangwq/article/details/124950935)
