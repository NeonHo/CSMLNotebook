在将Transformer[[Transformer]]应用于图像任务时，常见的做法是将CNN和Transformer进行端到端的联合训练。这意味着CNN和Transformer的参数会同时进行更新，以最小化整个模型的损失函数。

具体来说，整个模型可以分为两个主要组件：CNN编码器和Transformer解码器。CNN编码器负责对输入图像进行特征提取，生成一系列的特征向量。这些特征向量被送入Transformer解码器，解码器负责将这些特征向量转换为输出结果，例如图像分类、目标检测等。

在端到端的训练过程中，首先通过反向传播算法计算整个模型的损失函数梯度。然后，梯度会逐层传递回CNN和Transformer的参数，使它们同时进行更新。这种联合训练的方式可以使得CNN和Transformer在整个模型中相互影响和协同学习，以更好地适应图像任务的需求。

需要注意的是，有时候也可以选择先预训练CNN，再训练Transformer的方法。这种方法被称为"预训练-微调"（pretraining-finetuning）策略。在这种情况下，CNN首先在大规模的图像数据集上进行预训练，以学习通用的图像特征表示。然后，使用这些预训练的CNN参数初始化Transformer，并对整个模型进行微调，以适应具体的图像任务。这种策略可以在数据较为稀缺或任务复杂时提供更好的性能。

总之，端到端的联合训练是应用Transformer在图像任务中的常见做法，但有时也可以采用预训练-微调策略。具体选择哪种训练方式取决于任务的需求、数据集的规模以及计算资源的可用性等因素。