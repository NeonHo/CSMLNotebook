# Abstract
- brief introduction of ChatGPT and Bert
- data's influence
- The use and non-use cases of LLM
	- acknowledge intensive
	- traditional NL understanding
	- NL generation
	- emergent abilities
- The importance of Data
- The specific challenges
- 
- essential considerations for deployment of LLMs:
	- the impact of spurious biases
	- efficiency
	- cost
	- latency
# Introduction
- rapid development recently
- address multi NLP tasks.
- Effectively and efficiently requires understanding.

- Working with LLMs in downstream NLP tasks.
- Why or why not use LLMs
- How to select the most suitable LLM.
	- Model size
	- computational requirements
	- existing domain-specific pre-trained models.
- For better leverage the power

- Structure:
	- brief introduction to LLMs
		- GPT
		- BERT
	- critical factors from the data
		- pre-training data
		- training/tuning data
		- test data
	- various concrete NLP tasks
		- knowledge-intensive task
			- Q&A
			- conversation
			- inference
		- traditional NLU(Nature Language Understanding) tasks
			- 
